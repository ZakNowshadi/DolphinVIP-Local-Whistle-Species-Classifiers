
Brief Overview of Hyperparameter Optimisation

Basic Method One: Random
- Create a grid of possible values for hyperparameters
- Each iteration tries a random combinations from this grid and records performance
- At the end it returns the combination of hyperparameters that provides the best performance

Basic Method Two: Grid
- Creates a grid of possible values for hyperparameters
- Each iteration tries a combination in a specific order
- It fits the model on every combination of hyperparameters possible and records performance
- A the end it returns the best model with the best hyperparameters.

TOOLS 

SciKit Learn (and SciKit-optimise):
https://scikit-learn.org/stable/
https://scikit-optimize.github.io/stable/index.html
- Implementations for grid search and random search
- Trains and evaluates a model in a 'k fold cross-validation setting' over various parameter choices
 

Optuna:
https://optuna.org 
- Determines the promising area to search for optimizing to find the optimal hyperparameter in a minimum amount of time. 


HyperOpt:
http://hyperopt.github.io/hyperopt/
- Allows user to describe a search space where user expects the best results 
- Does random search, along with others like TPE and adaptive TPE


